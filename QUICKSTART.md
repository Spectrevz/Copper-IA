# Exemplo de Uso Simplificado - AI Copper

## üöÄ In√≠cio R√°pido

### 1. Crie um novo projeto

```bash
cargo new meu_projeto_ia
cd meu_projeto_ia
```

### 2. Adicione AI Copper ao Cargo.toml

```toml
[package]
name = "meu_projeto_ia"
version = "0.1.0"
edition = "2021"

[dependencies]
ai_copper = "0.1.3"
```

### 3. Use no seu c√≥digo

Edite `src/main.rs`:

```rust
use ai_copper::Tensor;

fn main() {
    println!("üéØ Testando AI Copper com download autom√°tico!");
    
    // Cria tensor com valores aleat√≥rios
    let tensor = Tensor::rand(3, 3);
    println!("Tensor aleat√≥rio:");
    tensor.print();
    
    // Opera√ß√µes matem√°ticas
    let result = tensor.relu().pow(2.0);
    println!("\nAp√≥s ReLU e elevado ao quadrado:");
    result.print();
    
    // Estat√≠sticas
    println!("\nEstat√≠sticas:");
    println!("M√©dia: {}", result.mean());
    println!("Desvio Padr√£o: {}", result.std());
    println!("M√°ximo: {}", result.max());
    println!("M√≠nimo: {}", result.min());
}
```

### 4. Compile e execute

```bash
cargo build
cargo run
```

**Na primeira vez:**
- O sistema ir√° baixar LibTorch e TensorFlow automaticamente
- Isso pode levar alguns minutos (download de ~260 MB)
- As bibliotecas ficam em cache para uso futuro

**Nas pr√≥ximas vezes:**
- A compila√ß√£o ser√° r√°pida
- As bibliotecas j√° estar√£o dispon√≠veis

## üìä Exemplo: Rede Neural Simples

```rust
use ai_copper::{Tensor, Linear};

fn main() {
    // Dados de entrada (4 amostras, 2 features cada)
    let x = Tensor::from_values(&[
        1.0, 2.0,  // amostra 1
        2.0, 3.0,  // amostra 2
        3.0, 4.0,  // amostra 3
        4.0, 5.0,  // amostra 4
    ], 4, 2);
    
    // Labels (4 amostras)
    let y = Tensor::from_values(&[0.0, 1.0, 1.0, 0.0], 4, 1);
    
    // Cria modelo linear (2 inputs -> 1 output)
    let model = Linear::new(2, 1);
    
    // Forward pass
    let predictions = model.forward(&x).sigmoid();
    
    println!("Predi√ß√µes:");
    predictions.print();
    
    println!("\nLabels verdadeiros:");
    y.print();
    
    // Calcula perda MSE
    let loss = predictions.mse_loss(&y);
    println!("\nPerda (MSE): {}", loss.sum());
}
```

## üé≤ Exemplo: Opera√ß√µes com Tensores

```rust
use ai_copper::Tensor;

fn main() {
    // Cria√ß√£o de tensores
    let zeros = Tensor::zeros(2, 3);
    let ones = Tensor::ones(2, 3);
    let identity = Tensor::eye(4);
    let random = Tensor::rand(3, 3);
    let normal = Tensor::randn(3, 3);
    
    println!("Matriz identidade 4x4:");
    identity.print();
    
    println!("\nDistribui√ß√£o normal:");
    normal.print();
    
    // Opera√ß√µes aritm√©ticas
    let a = Tensor::from_values(&[1.0, 2.0, 3.0], 1, 3);
    let b = Tensor::from_values(&[4.0, 5.0, 6.0], 1, 3);
    
    let soma = &a + &b;
    let produto = &a * &b;
    
    println!("\nA:");
    a.print();
    println!("B:");
    b.print();
    println!("A + B:");
    soma.print();
    println!("A * B:");
    produto.print();
    
    // Fun√ß√µes matem√°ticas
    let valores = Tensor::from_values(&[0.0, 1.57, 3.14], 1, 3);
    let senos = valores.sin();
    
    println!("\nSeno de [0, œÄ/2, œÄ]:");
    senos.print();
}
```

## üß† Exemplo: Treinamento de Rede Neural

```rust
use ai_copper::{Tensor, Linear, Optimizer};

fn main() {
    // Dados XOR
    let x_train = Tensor::from_values(&[
        0.0, 0.0,
        0.0, 1.0,
        1.0, 0.0,
        1.0, 1.0,
    ], 4, 2);
    
    let y_train = Tensor::from_values(&[
        0.0,
        1.0,
        1.0,
        0.0,
    ], 4, 1);
    
    // Modelo
    let layer1 = Linear::new(2, 4);  // 2 -> 4
    let layer2 = Linear::new(4, 1);  // 4 -> 1
    
    // Otimizador
    let mut optimizer = Optimizer::adam(&layer1, 0.01);
    
    // Treinamento
    println!("Iniciando treinamento...\n");
    
    for epoch in 0..1000 {
        // Forward
        let hidden = layer1.forward(&x_train).relu();
        let output = layer2.forward(&hidden).sigmoid();
        
        // Loss
        let loss = output.mse_loss(&y_train);
        
        // Backward
        loss.backward();
        
        // Update
        optimizer.step();
        
        if epoch % 100 == 0 {
            println!("√âpoca {}: Loss = {}", epoch, loss.sum());
        }
    }
    
    println!("\nTreinamento conclu√≠do!");
    
    // Teste
    let hidden = layer1.forward(&x_train).relu();
    let predictions = layer2.forward(&hidden).sigmoid();
    
    println!("\nPredi√ß√µes finais:");
    predictions.print();
    println!("\nLabels verdadeiros:");
    y_train.print();
}
```

## üîÑ Convers√£o entre Backends

```rust
use ai_copper::{Tensor, TensorBackend};

fn main() {
    // Cria tensor no LibTorch
    let tensor_torch = Tensor::rand(3, 3);
    
    println!("Tensor LibTorch:");
    tensor_torch.print();
    
    // Converte para TensorFlow
    let tensor_tf = tensor_torch.to_tensorflow();
    
    println!("\nMesmo tensor no TensorFlow:");
    tensor_tf.print();
    
    // Converte de volta
    let tensor_torch2 = tensor_tf.to_libtorch();
    
    println!("\nDe volta ao LibTorch:");
    tensor_torch2.print();
}
```

## üìù Dicas

### Apenas LibTorch (reduz download)

Se voc√™ s√≥ precisa do LibTorch:

```toml
[dependencies]
ai_copper = { version = "0.1.3", default-features = false, features = ["libtorch"] }
```

### Apenas TensorFlow (reduz download)

Se voc√™ s√≥ precisa do TensorFlow:

```toml
[dependencies]
ai_copper = { version = "0.1.3", default-features = false, features = ["tensorflow"] }
```

### Cache de Bibliotecas

As bibliotecas baixadas ficam em `deps/` e s√£o reutilizadas. Para for√ßar novo download:

```bash
# Windows
Remove-Item -Recurse -Force deps

# Linux/Mac
rm -rf deps
```

## üÜò Problemas?

Consulte [INSTALLATION.md](INSTALLATION.md) para troubleshooting detalhado.
