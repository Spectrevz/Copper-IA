# ðŸš€ AI Copper

**AI Copper** Ã© uma biblioteca Rust unificada que combina as capacidades do **LibTorch** (PyTorch C++) e **TensorFlow C API** em uma interface Ãºnica e conveniente. Crie modelos de machine learning e deep learning usando o melhor dos dois frameworks!

## âœ¨ CaracterÃ­sticas

### ðŸ”¥ Dual Backend Support
- **LibTorch Backend**: Acesso completo Ã s funcionalidades do PyTorch em C++
- **TensorFlow Backend**: Suporte nativo para TensorFlow C API
- **API Unificada**: Troque entre backends sem alterar seu cÃ³digo

### ðŸŽ¯ Funcionalidades Principais

#### Tensor Operations
- âœ… CriaÃ§Ã£o de tensores (zeros, ones, rand, randn, eye, from_values)
- âœ… OperaÃ§Ãµes aritmÃ©ticas (+, -, *, /)
- âœ… OperaÃ§Ãµes matriciais (matmul, transpose)
- âœ… EstatÃ­sticas (sum, mean, max, min, std, var, argmax, argmin)
- âœ… FunÃ§Ãµes matemÃ¡ticas (sin, cos, exp, log, sqrt, abs, pow)
- âœ… FunÃ§Ãµes de ativaÃ§Ã£o (relu, sigmoid, tanh)
- âœ… TransformaÃ§Ãµes (map, reshape, zeros_like, ones_like)
- âœ… ConversÃ£o entre backends

#### Neural Networks (LibTorch)
- âœ… Camadas Linear
- âœ… FunÃ§Ãµes de perda (MSE Loss, Cross Entropy Loss)
- âœ… FunÃ§Ãµes de ativaÃ§Ã£o (ReLU, Sigmoid, Tanh)
- âœ… Otimizadores (SGD, Adam)
- âœ… Backpropagation automÃ¡tica
- âœ… Treinamento de modelos

#### TensorFlow Integration
- âœ… Carregar modelos SavedModel
- âœ… Executar inferÃªncia
- âœ… ManipulaÃ§Ã£o de tensores multi-dimensionais
- âœ… OperaÃ§Ãµes tensoriais bÃ¡sicas

## ðŸ“¦ InstalaÃ§Ã£o

Adicione ao seu `Cargo.toml`:

```toml
[dependencies]
ai_copper = "0.1.3"
```

## âœ¨ Novidades v0.1.3

Esta versÃ£o adiciona **24 novas funÃ§Ãµes** focadas em Deep Learning moderno:

### ðŸ”¥ FunÃ§Ãµes de AtivaÃ§Ã£o
```rust
use ai_copper::Tensor;

let x = Tensor::from_values(&[-2.0, -1.0, 0.0, 1.0, 2.0], 1, 5);
let relu = x.relu();      // [0, 0, 0, 1, 2]
let sigmoid = x.sigmoid(); // Valores entre 0 e 1
let tanh = x.tanh();       // Valores entre -1 e 1
```

### ðŸ“ FunÃ§Ãµes MatemÃ¡ticas
```rust
let data = Tensor::rand(3, 3);
let sin_data = data.sin();      // Seno
let exp_data = data.exp();      // e^x
let sqrt_data = data.sqrt();    // Raiz quadrada
let pow_data = data.pow(2.0);   // x^2
```

### ðŸŽ² CriaÃ§Ã£o AvanÃ§ada de Tensores
```rust
let normal = Tensor::randn(3, 3);    // DistribuiÃ§Ã£o normal
let identity = Tensor::eye(5);       // Matriz identidade 5x5
let zeros = normal.zeros_like();     // Zeros com mesma forma
let ones = normal.ones_like();       // Uns com mesma forma
```

### ðŸ“Š EstatÃ­sticas AvanÃ§adas
```rust
let data = Tensor::from_values(&[1.0, 2.0, 3.0, 4.0, 5.0], 1, 5);
println!("Desvio PadrÃ£o: {}", data.std());  // ~1.414
println!("VariÃ¢ncia: {}", data.var());       // ~2.0
println!("Argmax: {}", data.argmax());       // 4 (Ã­ndice do mÃ¡ximo)
println!("Argmin: {}", data.argmin());       // 0 (Ã­ndice do mÃ­nimo)
```

### ðŸ§  Neural Networks Melhorados
```rust
use ai_copper::{Linear, Optimizer};

// Otimizador Adam (NOVO!)
let model = Linear::new(784, 10);
let optimizer = Optimizer::adam(&model, 0.001);

// ClassificaÃ§Ã£o com CrossEntropy (NOVO!)
let predictions = model.forward(&input).relu();
let loss = predictions.cross_entropy_loss(&labels);
loss.backward();
optimizer.step();
```

## ðŸŽ“ Exemplos de Uso

### 1. Usando LibTorch Diretamente

```rust
use ai_copper::Tensor;

fn main() {
    // Criar tensores
    let t1 = Tensor::ones(2, 3);
    let t2 = Tensor::rand(2, 3);
    let t3 = Tensor::from_values(&[1.0, 2.0, 3.0, 4.0], 2, 2);
    
    // OperaÃ§Ãµes
    println!("Soma: {}", t1.sum());
    println!("MÃ©dia: {}", t1.mean());
    
    // OperaÃ§Ãµes aritmÃ©ticas
    let t4 = t1 + t2;
    t4.print();
    
    // Transposta
    let t5 = t3.transpose();
    
    // MultiplicaÃ§Ã£o de matrizes
    let a = Tensor::from_values(&[1.0, 2.0, 3.0, 4.0], 2, 2);
    let b = Tensor::from_values(&[5.0, 6.0, 7.0, 8.0], 2, 2);
    let c = a.matmul(&b);
}
```

### 2. Usando TensorFlow

```rust
use ai_copper::{FlowTensors, TensorFlowModel};

fn main() {
    // VersÃ£o
    println!("TensorFlow: {}", FlowTensors::version_tf());
    
    // Criar tensores
    let t1 = FlowTensors::ones(&[2, 3]).unwrap();
    let t2 = FlowTensors::new(&[1.0, 2.0, 3.0, 4.0], &[2, 2]).unwrap();
    
    // OperaÃ§Ãµes
    println!("Soma: {}", t1.sum());
    println!("MÃ©dia: {}", t2.mean());
    
    // Transposta
    let t3 = t2.transpose().unwrap();
    
    // Carregar modelo
    let model = TensorFlowModel::load("model_path", "serve").unwrap();
    let outputs = model.run(&["input"], &[&t1], &["output"]).unwrap();
}
```

### 3. API Unificada - O Melhor dos Dois Mundos

```rust
use ai_copper::{UnifiedTensor, Backend, Device};

fn main() {
    let device = Device::CPU;
    
    // Usar LibTorch
    let t1 = UnifiedTensor::ones(2, 3, Backend::LibTorch, device);
    
    // Usar TensorFlow
    let t2 = UnifiedTensor::rand(2, 3, Backend::TensorFlow, device);
    
    // Converter entre backends
    let t3 = t2.to_backend(Backend::LibTorch);
    
    // OperaÃ§Ãµes funcionam independente do backend
    println!("Soma: {}", t3.sum());
    println!("MÃ©dia: {}", t3.mean());
    
    // OperaÃ§Ãµes aritmÃ©ticas
    let t4 = UnifiedTensor::from_values(&[1.0, 2.0, 3.0, 4.0], 2, 2, Backend::LibTorch, device);
    let t5 = UnifiedTensor::from_values(&[5.0, 6.0, 7.0, 8.0], 2, 2, Backend::LibTorch, device);
    let t6 = t4 + t5;
}
```

### 4. Treinamento de Modelos

```rust
use ai_copper::{Tensor, Linear, Optimizer};

fn main() {
    // Dados: y = 2*x + 1
    let x = Tensor::from_values(&[1.0, 2.0, 3.0, 4.0], 4, 1);
    let y = Tensor::from_values(&[3.0, 5.0, 7.0, 9.0], 4, 1);
    
    // Modelo
    let linear = Linear::new(1, 1);
    let optimizer = Optimizer::sgd(&linear, 0.01);
    
    // Treinar
    for epoch in 0..100 {
        let pred = linear.forward(&x);
        let loss = pred.mse_loss(&y);
        
        if epoch % 10 == 0 {
            println!("Epoch {}: Loss = {}", epoch, loss.as_slice()[0]);
        }
        
        loss.backward();
        optimizer.step();
    }
    
    // Testar
    let test = Tensor::from_values(&[5.0], 1, 1);
    let result = linear.forward(&test);
    result.print();
}
```

## ðŸ“š API Completa

### Tensor Operations (LibTorch)

```rust
// CriaÃ§Ã£o
Tensor::ones(rows, cols)
Tensor::zeros(rows, cols)
Tensor::rand(rows, cols)
Tensor::from_values(&values, rows, cols)

// OperaÃ§Ãµes
tensor.sum()
tensor.mean()
tensor.max()
tensor.min()
tensor.transpose()
tensor.reshape(new_rows, new_cols)
tensor.matmul(&other)
tensor.map(|x| x * 2.0)

// AritmÃ©tica
t1 + t2
t1 - t2
t1 * t2
t1 / t2

// Neural Networks
Linear::new(in_features, out_features)
linear.forward(&input)
tensor.mse_loss(&target)
tensor.backward()

Optimizer::sgd(&linear, learning_rate)
optimizer.step()
```

### TensorFlow Tensors

```rust
// CriaÃ§Ã£o
FlowTensors::new(&values, &dims)
FlowTensors::zeros(&dims)
FlowTensors::ones(&dims)

// OperaÃ§Ãµes
tensor.sum()
tensor.mean()
tensor.max()
tensor.min()
tensor.transpose()
tensor.reshape(&new_dims)
tensor.map(|x| x * 2.0)
tensor.data()
tensor.dims()

// Modelo
TensorFlowModel::load(path, tags)
model.run(&input_names, &inputs, &output_names)
```

### Unified API

```rust
// CriaÃ§Ã£o
UnifiedTensor::ones(rows, cols, backend, device)
UnifiedTensor::zeros(rows, cols, backend, device)
UnifiedTensor::rand(rows, cols, backend, device)
UnifiedTensor::from_values(&values, rows, cols, backend, device)

// ConversÃ£o
tensor.to_backend(Backend::TensorFlow)
tensor.backend()

// OperaÃ§Ãµes (mesmo API independente do backend)
tensor.sum()
tensor.mean()
tensor.max()
tensor.min()
tensor.transpose()
tensor.map(|x| x * 2.0)
tensor.shape()
```

## ðŸ—ï¸ Estrutura do Projeto

```
ai_copper/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ lib.rs                     # MÃ³dulo principal
â”‚   â”œâ”€â”€ unified/                   # API Unificada
â”‚   â”‚   â”œâ”€â”€ mod.rs
â”‚   â”‚   â”œâ”€â”€ tensor.rs             # UnifiedTensor
â”‚   â”‚   â”œâ”€â”€ backend.rs            # Backend enum
â”‚   â”‚   â””â”€â”€ device.rs             # Device enum
â”‚   â”œâ”€â”€ tensor_libortch/          # LibTorch backend
â”‚   â”‚   â”œâ”€â”€ mod.rs
â”‚   â”‚   â”œâ”€â”€ tensor.rs             # Tensor, Linear, Optimizer
â”‚   â”‚   â”œâ”€â”€ operators.rs          # Sobrecarga de operadores
â”‚   â”‚   â””â”€â”€ ffi.rs                # FFI bindings
â”‚   â””â”€â”€ tensor_tensorflow/        # TensorFlow backend
â”‚       â”œâ”€â”€ mod.rs
â”‚       â”œâ”€â”€ tensors_flow.rs       # FlowTensors, Model
â”‚       â””â”€â”€ ffi.rs                # FFI bindings
â”œâ”€â”€ cpp/
â”‚   â””â”€â”€ lib.cpp                   # ImplementaÃ§Ã£o C++
â”œâ”€â”€ examples/
â”‚   â””â”€â”€ basic_usage.rs            # Exemplos de uso
â”œâ”€â”€ Cargo.toml
â””â”€â”€ README.md
```

## ðŸ”§ Requisitos

- Rust 2021 edition ou superior
- LibTorch (para funcionalidades LibTorch)
- TensorFlow C API (para funcionalidades TensorFlow)
- CMake (para compilaÃ§Ã£o C++)
- Compilador C++ compatÃ­vel

## ðŸš€ Como Compilar

```bash
# Clone o repositÃ³rio
git clone https://github.com/seu_usuario/ai_copper.git
cd ai_copper

# Compile
cargo build --release

# Execute exemplos
cargo run --example basic_usage

# Execute testes
cargo test
```

## ðŸ“– DocumentaÃ§Ã£o

Gere a documentaÃ§Ã£o completa com:

```bash
cargo doc --open
```

## ðŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Sinta-se Ã  vontade para abrir issues e pull requests.

## ðŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT - veja o arquivo LICENSE para detalhes.

## ðŸ‘¨â€ðŸ’» Autores

**Ryan Lima** - [ryan2020gary@gmail.com](mailto:ryan2020gary@gmail.com)
**Rodrigo Dias** - [rodrigods.dev@gmail.com](mailto:rodrigods.dev@gmail.com)

## ðŸŒŸ Agradecimentos

- PyTorch Team pela excelente biblioteca LibTorch
- TensorFlow Team pela TensorFlow C API
- Comunidade Rust pelo ecossistema incrÃ­vel

---

**Made with â¤ï¸ and Rust ðŸ¦€**


**`ai_copper`** is a library developed for the **`Copper language`**, written in Rust with revamped C++ functions, which provides connections to **`PyTorch's`** libtorch C++ library and **`TensorFlow's`** C++ library. It allows you to create and manipulate tensors, perform machine learning operations, and use pre-trained TensorFlow models directly in Copper. The library is designed to facilitate integration between Copper, Rust, and C++ in projects that use libtorch and TensorFlow for machine learning implementations.

## Features

- Create tensors directly in Rust using `libtorch`.
- Support for basic tensor manipulation operations.
- Easy integration with PyTorch for running machine learning models in Rust.
- Support for TensorFlow C++ library integration.

## Requirements

- **Rust**: The library is designed to work with the latest version of Rust.
- **C++**: A C++ compiler (such as g++ or Clang) must be installed on the system.
- **CMake**: You must have [CMake](https://cmake.org/download/) installed and available in your PATH.
- **MSVC/Build Tools (Windows)**: On Windows, you need the [Microsoft Visual Studio Build Tools](https://visualstudio.microsoft.com/visual-cpp-build-tools/) (MSVC) with the C++ workload enabled.
- **libtorch**: The PyTorch C++ library (CPU version) must be installed on your system.
- **TensorFlow C++**: The TensorFlow C++ library (CPU version) must be installed on your system (optional, for TensorFlow integration)(https://www.tensorflow.org/install/lang_c?hl=pt-br).
- **Copper**: The Copper language must be configured in the environment to use the library.

## Environment variables

### Windows

- `LIBTORCH` â€” Path to the root of libtorch (e.g., `C:\libtorch`)
- `TENSORFLOW_ROOT` â€” Path to the root of TensorFlow C++ (e.g., `C:\libtensorflow`)

How to set (temporary, for the current terminal only):

```powershell
$env:LIBTORCH = "C:\libtorch"
$env:TENSORFLOW_ROOT = "C:\libtensorflow"
```

Or set permanently via Control Panel â†’ System â†’ Advanced â†’ Environment Variables.

> The build.rs will automatically copy the required DLLs from `libtorch/lib` and `libtensorflow/lib` to the executable directory.

### Linux

Set the environment variables:

```bash
export LIBTORCH=/home/youruser/libtorch
export TENSORFLOW_ROOT=/home/youruser/libtensorflow
```

For temporary use, run the commands above in the terminal before building.

To make it permanent, add to the end of your `~/.bashrc` or `~/.zshrc`:

```bash
export LIBTORCH=/home/youruser/libtorch
export TENSORFLOW_ROOT=/home/youruser/libtensorflow
```

> The build.rs will automatically copy the required .so libraries from `libtorch/lib` and `libtensorflow/lib` to the executable directory.

**Attention:** If the variables are not set correctly, the build will fail or the executable will not find the required libraries at runtime.

## Installation

**Windows**

To add `ai_copper` to your Rust project, simply include the following line in your `Cargo.toml:`

```toml
[dependencies]
ai_copper = { git = "https://github.com/CopperRS/ai_copper.git" }
```

Then, run:

```
cargo build
cargo run
```

> The build script automatically copies the necessary DLLs from libtorch and TensorFlow folders to your target directory.  
> You do **not** need to manually copy DLLs or adjust the PATH after setup.

---

**Linux**

To use `ai_copper` on Linux, you need to clone the repository and build it locally to generate the shared library (`libai_copper.so`). Follow these steps:

1. Clone the Repository:

```bash
git clone https://github.com/CopperRS/ai_copper.git
cd ai_copper
```

2. Install to cmake and g++ or clang

**`Terminal`**

```
#g++
sudo apt-get install build-essential

#clang
sudo apt-get install clang

#cmake
sudo apt-get install cmake
```

3. Create the .so file to use the lib.

**`Terminal`**

```
cd cpp
mkdir build && cd build
cmake ..
cmake --build .
cd ../..
cargo build
```

4. Add as a Local Dependency: In your project's `Cargo.toml`, add `ai_copper` as a path dependency, pointing to the cloned repository:

```toml
[dependencies]
ai_copper = { path = "/path/to/ai_copper" }
```

Replace `/path/to/ai_copper` with the actual path where you cloned the repository

5. Build the Project: Run the following command in your project directory to build the project and generate the `libai_copper.so` file

```bash
cargo build
```

This will create the shared library in `/path/to/ai_copper/cpp/build`.

6. Run the Project: Before running your project, set the `LD_LIBRARY_PATH` to include the directory containing `libai_copper.so`, libtorch, and TensorFlow libs:

**_If you haven't defined the variables permanently, you can temporarily set them to run at runtime._**

```bash
export LIBTORCH_PATH=/home/yourname/libtorch
export TENSORFLOW_ROOT=/home/yourname/libtensorflow
export LD_LIBRARY_PATH=/path/to/ai_copper/cpp/build:$LIBTORCH_PATH/lib:$TENSORFLOW_ROOT/lib:$LD_LIBRARY_PATH
cargo run
```

---

**Notes**

- Ensure that the TensorFlow C++ package you use contains the DLLs (`.dll`) on Windows or shared objects (`.so`) on Linux inside the `lib` folder.
- The build script of `ai_copper` will handle copying DLLs automatically on Windows.
- On Linux, it is essential to have your `LD_LIBRARY_PATH` correctly set so that runtime linking works.
- This setup allows you to use both PyTorch (`libtorch`) and TensorFlow C++ APIs seamlessly within Rust using `ai_copper`.

